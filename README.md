# Snake AI com Q-Learning

Este projeto implementa um agente de Intelig√™ncia Artificial que aprende a jogar Snake usando **Q-Learning**, um algoritmo de aprendizado por refor√ßo. O agente aprende atrav√©s da experi√™ncia, melhorando sua performance ao longo dos epis√≥dios de treinamento.

## üìã Descri√ß√£o

O projeto consiste em:

- **Jogo Snake**: Implementado com pygame, onde a cobra deve comer frutas sem bater nas paredes ou em si mesma
- **Agente Q-Learning**: IA que aprende a jogar atrav√©s de tentativa e erro
- **Visualiza√ß√£o**: Interface gr√°fica para acompanhar o treinamento e gr√°ficos de progresso
- **Otimiza√ß√£o**: Interface aparece apenas a cada 50 jogos para acelerar o treinamento

## üéÆ Como Funciona

### Estados

O agente observa 11 caracter√≠sticas do ambiente:

- **Perigos** (3): Reto, direita, esquerda
- **Dire√ß√£o atual** (4): Esquerda, direita, cima, baixo
- **Localiza√ß√£o da comida** (4): Esquerda, direita, cima, baixo da cabe√ßa

### A√ß√µes

- **[1,0,0]**: Continuar reto
- **[0,1,0]**: Virar √† direita
- **[0,0,1]**: Virar √† esquerda

### Recompensas

- **+10**: Comer uma fruta
- **-10**: Colidir (game over)
- **0**: Movimento normal

## üöÄ Como Executar

### Pr√©-requisitos

```bash
pip install -r requirements.txt
```

### Executar o Treinamento

```bash
python3 train.py
```

### Estrutura do Projeto

```
q-learning/
‚îú‚îÄ‚îÄ agent.py           # Implementa√ß√£o do agente Q-Learning
‚îú‚îÄ‚îÄ snake.py           # Jogo Snake com pygame
‚îú‚îÄ‚îÄ train.py           # Script principal de treinamento
‚îú‚îÄ‚îÄ requirements.txt   # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md         # Este arquivo
```

## üß† Algoritmo Q-Learning

### Par√¢metros

- **Alpha (Œ± = 0.1)**: Taxa de aprendizado
- **Gamma (Œ≥ = 0.9)**: Fator de desconto
- **Epsilon (Œµ)**: Taxa de explora√ß√£o (inicia em 0.8, decai gradualmente)

### F√≥rmula de Atualiza√ß√£o

```
Q(s,a) = Q(s,a) + Œ± * [r + Œ≥ * max(Q(s',a')) - Q(s,a)]
```

Onde:

- `s`: Estado atual
- `a`: A√ß√£o tomada
- `r`: Recompensa recebida
- `s'`: Pr√≥ximo estado
- `Œ±`: Taxa de aprendizado
- `Œ≥`: Fator de desconto

## üìä Visualiza√ß√µes

### Interface do Jogo

- **Cobra**: Azul com cabe√ßa verde
- **Comida**: Vermelho
- **Score**: Pontua√ß√£o atual
- **Game**: N√∫mero do epis√≥dio atual

### Gr√°fico de Progresso

- **Linha azul**: Score de cada jogo
- **Linha vermelha**: M√©dia m√≥vel dos scores
- Atualizado a cada 5 jogos

### Estat√≠sticas no Terminal

```
Game  150 | Score:  3 | Record:  8 | Mean: 2.1 | Epsilon: 0.020 | Q-States: 245
```

## ‚öôÔ∏è Configura√ß√µes

### Modificar Frequ√™ncia da Interface

Em `train.py`:

```python
show_ui = (agent.n_games % 50 == 0 and agent.n_games > 0) or agent.n_games == 0
```

Altere `50` para o intervalo desejado.

### Ajustar Velocidade do Jogo

Em `snake.py`:

```python
SPEED = 40  # FPS quando a interface est√° ativa
```

### Modificar Hiperpar√¢metros

Em `train.py`:

```python
agent = Agent(q_table={}, alpha=0.1, gamma=0.9, epsilon=0.8)
```

### M√©tricas de Performance

- **Q-States**: N√∫mero de estados √∫nicos na tabela Q
- **Epsilon**: Diminui gradualmente (explora√ß√£o ‚Üí explora√ß√£o)
- **Mean Score**: M√©dia dos √∫ltimos jogos

## üîß Personaliza√ß√£o

### Modificar Recompensas

Em `snake.py`, m√©todo `play_step()`:

```python
if reward_eaten:
    reward = 10    # Recompensa por comer
else:
    reward = 0     # Sem penalidade por movimento

if self.is_collision():
    reward = -10   # Penalidade por colidir
```

### Alterar Estado do Agente

Em `snake.py`, m√©todo `get_state()`:

```python
state = [
    # Adicione novas caracter√≠sticas aqui
    # Exemplo: dist√¢ncia at√© a comida, tamanho da cobra, etc.
]
```

## üìÑ Licen√ßa

Este projeto √© desenvolvido para fins educacionais como parte do curso de Intelig√™ncia Artificial da FCT UNESP.
